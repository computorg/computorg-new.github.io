---
layout: page
permalink: /review/
title: Review
description: Guidelines for reviewing a contribution to Computo
order: 4
nav: true
---

## Overview

Computo  relies  on  [Scholastica](https://computo.scholasticahq.com/)
for the review process. The review form is text based but Markdown and
LaTeX formatting is supported so you  can add hyperlinks and use LaTeX
to add equations in your review. Reviewers are also required to answer
a handful  of rating  scale questions  about the  submission. Detailed
information on the  review process in Scholastica can be  found in the
[Scholastica                                                  reviewer
guide](https://help.scholasticahq.com/article/97-reviewer-guide).

## Guidelines for evaluation

In order to help you in performing your review we provide a list of the main questions we are trying to answer when evaluating a submission:

1. Is the paper within the scope of Computo?

    See [https://computo.sfds.asso.fr/about](Aims and Scope) of Computo.

2. Is the paper clearly written?

    Computo is intended for computational scientists in statistics/machine learning. The Abstract and Introduction should be as nontechnical as possible, and provide a clear description of the contributions of the paper. Strength and limitations of the work should be adequately discussed, in particular in relation to related work. Graphs and tables should be well thought out and uncluttered.

3. Is the paper correct?

    Mathematical and algorithmic validity are the authors' professional responsibility. Referees can spot errors of reasoning, but are not expected to perform line-by-line checks of technical results.

4. Is the paper adequately evaluated?

    Are all claims clearly articulated and supported either by empirical experiments or theoretical analyses? If appropriate, have the authors implemented their work and demonstrated its utility on a significant problem?

5. Is the paper reproducible?

    The reproducibility of numerical results is a necessary condition for publication in Computo. The referees are expected to check whether they can run the code provided by the authors to reproduce their results. In case of major reproducibility issues, the referees should warn the Associate Editor as soon as possible.
